{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMOixNVt3OCJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/sample_data/spam.csv', encoding='ISO-8859-1')"
      ],
      "metadata": {
        "id": "8N28gvjQ4HDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "tVrv_WFb4MSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "eUOwUJWE6I7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***1. Data Cleaning***"
      ],
      "metadata": {
        "id": "crB-MbSaIhrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " df.info() # checking wether columns are needed or not."
      ],
      "metadata": {
        "id": "g5z7ylpp6Zlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in 2,3,4 columns values are empty\n",
        "'''So we will drop last 3 columns'''\n",
        "df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'],inplace=True)"
      ],
      "metadata": {
        "id": "uWIj3gyTJBQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "7RImO9TrJa1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# renaming the columns for better understanding\n",
        "df.rename(columns={'v1':'target','v2':'text'},inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "_L1iu1M2J_Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()"
      ],
      "metadata": {
        "id": "K7bIZbzTL9Ho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['target']=encoder.fit_transform(df['target']) # to assign 0 value to ham and 1 value to spam"
      ],
      "metadata": {
        "id": "-YvfnG0SjroP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "ymWdYDuoGC4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# missing values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "Q90SnbkAGV4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking for duplicate values\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "IBIJ0oIvGgfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop_duplicates(keep='first')"
      ],
      "metadata": {
        "id": "gGmTUw7dGnEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "dCWD6g2FGxgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "jr7n1nB2GzfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***2. EDA***"
      ],
      "metadata": {
        "id": "jE4g83kWHEIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking percentage of ham and spam\n",
        "df['target'].value_counts()"
      ],
      "metadata": {
        "id": "sh5TaRKvG05a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.pie(df['target'].value_counts(),labels=['ham','spam'],autopct=\"%0.2f\",colors=['green','red'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pLV5OIsUHsZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data is not balanced"
      ],
      "metadata": {
        "id": "T_vcEZ3rH1Bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "JbmQoLWsICvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "svinDf2bItKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['num_characters']=df['text'].apply(len)"
      ],
      "metadata": {
        "id": "RRw03s9YINMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "GODAN6blIZko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fetching num of words\n",
        "df['num_words']=df['text'].apply(lambda x:len(nltk.word_tokenize(x)))  # dividing sentence on basis of words"
      ],
      "metadata": {
        "id": "RjBxRXJ4IkHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_df=df.copy()"
      ],
      "metadata": {
        "id": "g0JojdczJfUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['num_sentences']=df['text'].apply(lambda x:len(nltk.sent_tokenize(x))) #dividing the sentence on basis of small sentences"
      ],
      "metadata": {
        "id": "4t0MVsmRKFVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['num_characters', 'num_words' , 'num_sentences']].describe()"
      ],
      "metadata": {
        "id": "ru_-LcKWKMyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is for ham messages\n",
        "df[df['target']==0][['num_characters','num_words', 'num_sentences']].describe()"
      ],
      "metadata": {
        "id": "hs1ihgw8K1MV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is for spam messages\n",
        "df[df['target']==1][['num_characters','num_words', 'num_sentences']].describe()"
      ],
      "metadata": {
        "id": "CjZiM20ILQRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "jO7aNlJ0LiTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(df[df['target']==0]['num_characters'],color='green')\n",
        "sns.histplot(df[df['target']==1]['num_characters'],color='red')"
      ],
      "metadata": {
        "id": "HlTuiJD4ME8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(df[df['target']==0]['num_sentences'],color='green')\n",
        "sns.histplot(df[df['target']==1]['num_sentences'],color='red')"
      ],
      "metadata": {
        "id": "bjfsckXrMRz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking relationship of number of words with sentences\n",
        "sns.pairplot(df,hue='target',vars=['num_characters','num_words','num_sentences'],palette='Set1')"
      ],
      "metadata": {
        "id": "A2uKEBhrNBo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# it tells data has outlier"
      ],
      "metadata": {
        "id": "9pPu4A87NbQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns=['text'],inplace=True) # for applying correlation"
      ],
      "metadata": {
        "id": "5gjEAK7sOD_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(df.corr(),annot=True,cmap='cividis')"
      ],
      "metadata": {
        "id": "mKh9hJN1O67B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Data Preprocessing ---> ***LowerCase>Tokenization>RemoveSpeacialCharacters>RemovingStopwords(like is , of , the)>Stemming/Lemitization(converting danced,dancing to dance only)"
      ],
      "metadata": {
        "id": "VDgU5VB9RSqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def text_transform(text):\n",
        "  text=text.lower()\n",
        "  text=nltk.word_tokenize(text)\n",
        "\n",
        "  y=[]\n",
        "  for i in text:\n",
        "    if i.isalnum():\n",
        "      y.append(i)\n",
        "\n",
        "\n",
        "  text=y[:] #cloning\n",
        "  y.clear()\n",
        "\n",
        "  for i in text:\n",
        "    if i not in stopwords.words('english') and i not in string.punctuation: #for removing stopwords\n",
        "      y.append(i)\n",
        "\n",
        "  text=y[:] #cloning\n",
        "  y.clear()\n",
        "\n",
        "  for i in text:\n",
        "    y.append(ps.stem(i))\n",
        "\n",
        "\n",
        "  return  \" \" .join(y)"
      ],
      "metadata": {
        "id": "zzth1F6YpMQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Stemming\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps=PorterStemmer()\n",
        "ps.stem('dancing')"
      ],
      "metadata": {
        "id": "rUoxLV7TrJxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_df"
      ],
      "metadata": {
        "id": "XI4sbPLItCMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_df['text'][0]"
      ],
      "metadata": {
        "id": "S8sWA6TxvYuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_df['transformed_text']=main_df['text'].apply(text_transform)"
      ],
      "metadata": {
        "id": "gM_1B6zNyEqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_df.head()"
      ],
      "metadata": {
        "id": "uvaEH4ZGyi5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " from wordcloud import WordCloud\n",
        " wc=WordCloud(width=500,height=500,min_font_size=10,background_color='red')"
      ],
      "metadata": {
        "id": "AD1ZVIzmy5F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Spam messages\n",
        "spam_wc= wc.generate(main_df[main_df['target']==1]['transformed_text'].str.cat(sep=\" \"))\n",
        "plt.imshow(spam_wc)"
      ],
      "metadata": {
        "id": "LGLiJw2mzZ-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For Ham Messages\n",
        "wc=WordCloud(width=500,height=500,min_font_size=10,background_color='green')\n",
        "ham_wc= wc.generate(main_df[main_df['target']==0]['transformed_text'].str.cat(sep=\" \"))\n",
        "plt.imshow(ham_wc)"
      ],
      "metadata": {
        "id": "8A4GLuy5z1nT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_df.head()"
      ],
      "metadata": {
        "id": "cr8jSGnO0iZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding top 30 words of spam messages\n",
        "spam_corpus=[]  # for spam messages\n",
        "for msg in main_df[main_df['target']==1]['transformed_text'].tolist():\n",
        "    for word in msg.split():\n",
        "        spam_corpus.append(word)"
      ],
      "metadata": {
        "id": "YfapJZHc2j4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(spam_corpus)"
      ],
      "metadata": {
        "id": "eeQil2qg3GSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Before plotting\n",
        "from collections import Counter\n",
        "fig, ax = plt.subplots()\n",
        "ax.set_facecolor('red')\n",
        "sns.barplot(x=pd.DataFrame(Counter(spam_corpus).most_common(30))[0],y=pd.DataFrame(Counter(spam_corpus).most_common(30))[1], palette=\"viridis\" ,color='red')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JUWHNU1U3hzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding top 30 words of ham messages\n",
        "ham_corpus = []  # for ham messages\n",
        "for msg in main_df[main_df['target']==0]['transformed_text'].tolist():\n",
        "    for word in msg.split():\n",
        "        ham_corpus.append(word)"
      ],
      "metadata": {
        "id": "_YOGHftr32Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(ham_corpus)"
      ],
      "metadata": {
        "id": "DwjbaCyS6Vl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.set_facecolor('green')\n",
        "sns.barplot(x=pd.DataFrame(Counter(ham_corpus).most_common(30))[0],y=pd.DataFrame(Counter(ham_corpus).most_common(30))[1], palette=\"viridis\" )\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RDBXJuZV6aGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***4. Model Building***"
      ],
      "metadata": {
        "id": "Vjy0Rgkf_3rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_df.head()"
      ],
      "metadata": {
        "id": "idgQeNG9AEM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will vectorize using bag of words"
      ],
      "metadata": {
        "id": "O9Ra34K3AQSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "cv=CountVectorizer()\n",
        "tfidf=TfidfVectorizer()"
      ],
      "metadata": {
        "id": "6-H0KvteAk3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = tfidf.fit_transform(main_df['transformed_text']).toarray() # we need only numerical data"
      ],
      "metadata": {
        "id": "3PXOWxEGAvkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape #5169->sms , 6708 words"
      ],
      "metadata": {
        "id": "8lLQtJSEA2WU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=df['target'].values\n",
        "y"
      ],
      "metadata": {
        "id": "caA_osJgA3nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "00DvlH7nBIE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=2)"
      ],
      "metadata": {
        "id": "YUtWRbg9BPYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score"
      ],
      "metadata": {
        "id": "cNO3KLC1BVOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnb=GaussianNB()\n",
        "mnb=MultinomialNB()\n",
        "bnb=BernoulliNB()"
      ],
      "metadata": {
        "id": "vCJMGMTZBbpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Gaussian\n",
        "gnb.fit(X_train,y_train)\n",
        "y_pred1=gnb.predict(X_test)\n",
        "print(accuracy_score(y_test,y_pred1))\n",
        "print(confusion_matrix(y_test,y_pred1))\n",
        "print(precision_score(y_test,y_pred1))"
      ],
      "metadata": {
        "id": "qusr8nf9BfcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Multinnomial\n",
        "mnb.fit(X_train,y_train)\n",
        "y_pred2=mnb.predict(X_test)\n",
        "print(accuracy_score(y_test,y_pred2))\n",
        "print(confusion_matrix(y_test,y_pred2))\n",
        "print(precision_score(y_test,y_pred2))"
      ],
      "metadata": {
        "id": "6ONJ9f6KB0nA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Bernoulii\n",
        "bnb.fit(X_train,y_train)\n",
        "y_pred3=mnb.predict(X_test)\n",
        "print(accuracy_score(y_test,y_pred3))\n",
        "print(confusion_matrix(y_test,y_pred3))\n",
        "print(precision_score(y_test,y_pred3))"
      ],
      "metadata": {
        "id": "3rranRynCGr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tfidf we have used then mnb"
      ],
      "metadata": {
        "id": "aeFV2VTPDaUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imported all Classifiers\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "Ow8TrVZHE6d5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Called objects here and setted all the hyperparameters\n",
        "svc=SVC(kernel='sigmoid',gamma=1.0)\n",
        "knc=KNeighborsClassifier()\n",
        "mnb=MultinomialNB()\n",
        "dtc=DecisionTreeClassifier(max_depth=5)\n",
        "lrc=LogisticRegression(solver='liblinear',penalty='l1')\n",
        "rfc=RandomForestClassifier(n_estimators=50,random_state=2)\n",
        "abc=AdaBoostClassifier(n_estimators=50,random_state=2)\n",
        "etc=ExtraTreesClassifier(n_estimators=50,random_state=2)\n",
        "gbdt=GradientBoostingClassifier(n_estimators=50,random_state=2)\n",
        "xgb=XGBClassifier(n_estimators=50,random_state=2)"
      ],
      "metadata": {
        "id": "Mv7djx6KFS20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf ={\n",
        "    'SVC':svc,\n",
        "    'KNN':knc,\n",
        "    'NB':mnb,\n",
        "    'DT':dtc,\n",
        "    'LR':lrc,\n",
        "    'RF':rfc,\n",
        "    'AdaBoost':abc,\n",
        "    'ETC':etc,\n",
        "    'GBDT':gbdt,\n",
        "    'XGB':xgb\n",
        "}"
      ],
      "metadata": {
        "id": "hI2Q5c4qFsNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_classifier(clf,X_train,y_train,X_test,y_test):\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_pred=clf.predict(X_test)\n",
        "  accuracy=accuracy_score(y_test,y_pred)\n",
        "  precision=precision_score(y_test,y_pred)\n",
        "\n",
        "  return accuracy,precision"
      ],
      "metadata": {
        "id": "CKO-315pHK3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# eg of running any classifier\n",
        "train_classifier(dtc,X_train,y_train,X_test,y_test) # in output: (precision , accuracy)"
      ],
      "metadata": {
        "id": "CqFkF7a9HQbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applied a loop on dictionary clfs and picked every algo trained the model and stored accuracy score for every algorithim\n",
        "accuracy_scores=[]\n",
        "precision_scores=[]\n",
        "\n",
        "for name,clf in clf.items():\n",
        "  current_accuracy,current_precision=train_classifier(clf,X_train,y_train,X_test,y_test)\n",
        "  print(\"For \",name)\n",
        "  print(\"Accuracy - \",current_accuracy)\n",
        "  print(\"Precision - \",current_precision)\n",
        "\n",
        "  accuracy_scores.append(current_accuracy)\n",
        "  precision_scores.append(current_precision)"
      ],
      "metadata": {
        "id": "S9pwYdXmHeGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "performance_df=pd.DataFrame({'Algorithm':clf.keys(),'Accuracy':accuracy_scores,'Precision':precision_scores}).sort_values('Precision',ascending=False)"
      ],
      "metadata": {
        "id": "C9YY9QAfK4wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "performance_df"
      ],
      "metadata": {
        "id": "Y2beK-0mLdhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='Algorithm',y='Accuracy',data=performance_df,palette='viridis')"
      ],
      "metadata": {
        "id": "dQqs6xx3Lspb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now Conveting this to a website"
      ],
      "metadata": {
        "id": "a2a42vwsMIUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "pickle.dump(tfidf,open('vectorizer.pkl','wb'))\n",
        "pickle.dump(mnb,open('model.pkl','wb'))"
      ],
      "metadata": {
        "id": "o_2c0_zbMT9o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}